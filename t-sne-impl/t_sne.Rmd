---
title: "t_sne"
author: "Luis Angel Rodriguez Garcia"
date: "3/5/2022"
header-includes:
  - \usepackage{amsmath}
  - \usepackage[makeroom]{cancel}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

```{r, include=FALSE}
library(dplyr)
library(numDeriv)
```

We are going to play with the Iris dataset:

```{r}
X <- iris %>% dplyr::select(-Species) %>% as.matrix()
n <- nrow(X)
p <- ncol(X)
```

## Euclidean distance

The way to calculate the Euclidean distance:

$$
\|\mathbf{x}_i-\mathbf{x}_j\|^2 = \|\mathbf{x}_i\|^2 + \|\mathbf{x}_j\|^2 - 2\mathbf{x}_i'\mathbf{x}_j
$$

where $\|\mathbf{x}_i\| = \sqrt{x_{i,1}^2 + \dots + x_{i,p}^2}$ and $\mathbf{x}_k^2 = \mathbf{x}_k'\mathbf{x}_k = x_{k1}^2 + ... + x_{kp}^2$.

The following method apply the formula above:

```{r iris}
x_diff <- function(X) {
  n <- nrow(X)
  sum_x <- apply(X^2, MARGIN=1, FUN=sum)
  sum_x_m <- t(matrix(replicate(n, sum_x), byrow=T, nrow=n))
  cross_times_minus_2 <- -2 * (X %*% t(X))
  D <- t(cross_times_minus_2 + sum_x_m) + sum_x_m
  D <- round(D, digits=4) 
}
```

## Perplexity

$$
Perp_i = 2^{H_i}
$$

Where $H_i$ is the Shannon entropy in the point $x_i$ of the conditional probability:

```{=tex}
\begin{equation}
\begin{split}
H_i  & = - \sum_{j\neq i}p_{j|i}\log(p_{j|i}) \\
     & = - \sum_{j\neq i}p_{j|i}\log(\frac{p_{j,i}}{p_{i}}) \\
     & = - \sum_{j\neq i}p_{j|i}(\log(p_{j,i})-\log(p_{i})) \\
     & = - \sum_{j\neq i}p_{j|i}(\log(e^{-||x_i-x_j||^2/2\sigma^2})-\log(\sum_{k\neq i}e^{-||x_i-x_j||^2/2\sigma^2})) \\
     & = - \sum_{j\neq i}p_{j|i}((-||x_i-x_j||^2/2\sigma^2)-\log(\sum_{k\neq i}e^{-||x_i-x_j||^2/2\sigma^2})) \\
     & = \sum_{j\neq i}p_{j|i}(\log(S_i)+||x_i-x_j||^2\frac{1}{2\sigma^2}) \\
     & = \log(S_i)\sum_{j\neq i}p_{j|i} + \frac{1}{2\sigma^2}\sum_{j\neq i}p_{j|i} ||x_i-x_j||^2) \\
     & = \log(S_i)+\frac{1}{2\sigma^2}\sum_{j\neq i}p_{j|i}||x_i-x_j||^2
\end{split}
\end{equation}
```
Where $S_i=\sum_{k\neq i}e^{-||x_i-x_j||^2/2\sigma^2}$ and $\sum_{j\neq i}p_{j|i}=1$

In order to proceed with the optimization of the variance, we are going to define this term $\frac{1}{2\sigma^2}$ as the parameter $\beta$.

```{r}
entropy_beta <- function(D_i, beta=1) {
  P_i <- exp(-D_i * beta)
  sum_p_i <- sum(P_i)
  H_i <- log(sum_p_i) + (beta * sum(D_i * P_i) /sum_p_i) 
  P_i <- P_i / sum_p_i
  return(list(entropy=H_i, probs=P_i))
}
```

The goal is to adjust the variability so that the perplexity at each point is the same. The perplexity is a way to measure the effective number of neighbors of a point. We are going to perform a binary search to get the probabilities in such a way that the conditional Gaussian has the same perplexity.

```{r}
index_except_i <- function(i, n) {
  index <- c(seq(1,i-1),seq(i+1,n))
  if (i == 1) {
    index <- 2:n
  } else if (i == n) {
    index <- 1:(n-1)
  }
  return(index)
}

binary_search <- function(h_diff, beta, i, beta_min, beta_max) {
  if(h_diff > 0) {
    beta_min = beta[i]
    if(beta_max == -Inf || beta_max == Inf) {
      beta[i] <- beta[i] * 2
    } else {
      beta[i] <- (beta[i] + beta_max) / 2
    }
  } else {
    beta_max = beta[i]
    if(beta_min == -Inf || beta_min == Inf) {
      beta[i] <- beta[i] / 2
    } else {
      beta[i] <- (beta[i] + beta_min) / 2
    }
  }
  return(list(beta=beta, min=beta_min, max=beta_max))
}

binary_search_optimization <- function(D_i, i, beta, h_star, prob_star, log_perp, 
                                       tolerance=1e-5) {
  beta_min <- -Inf
  beta_max <- Inf
  tries <- 0
  h_diff <- h_star - log_perp
  
  while(abs(h_diff) > tolerance && tries < 50) {
    beta_opt <- binary_search(h_diff, beta, i, beta_min, beta_max)
    beta <- beta_opt$beta; beta_min <- beta_opt$min; beta_max <- beta_opt$max
    
    res_loop <- entropy_beta(D_i, beta[i])
    h_star <- res_loop$entropy; prob_star <- res_loop$probs
    
    h_diff <- h_star - log_perp
    tries <- tries + 1 
  }
  return(list(probs=prob_star, beta=beta))
}

```

Once we have defined these two methods, we are able to obtain the high dimensional properties:

```{r}

high_dimension_probs <- function(X=matrix(), tolerance=1e-5, perplexity=30) {
  n <- nrow(X)
  p <- ncol(X)
  
  D <- x_diff(X)
  
  P <- matrix(0, nrow=150, ncol=150)
  beta <- rep(1, n)
  log_perp <- log(perplexity)
  
  for(i in seq_len(n)) {
    column_index <- index_except_i(i, n)
    D_i <- D[i, column_index]
    
    res <- entropy_beta(D_i, beta[i])
    h_star <- res$entropy
    prob_star <- res$probs
    
    h_diff <- h_star - log_perp
    
    res_opt = binary_search_optimization(D_i, i, beta, h_star, prob_star, 
                                           log_perp, tolerance)
    prob_star = res_opt$probs; beta = res_opt$beta
    
    P[i, column_index] <- prob_star
  }
  print("Values of sigma for each x_i")
  print(sqrt(1/beta))
  print(sprintf("Mean value of sigma: %01.2f", mean(sqrt(1/beta))))
  return(P)
}
```

The version of the t-SNE is the symmetric one, that has the property that $p_{ij} = p_{ji}$ and $q_{ij}=q_{ji} \quad \forall i,j$. Therefore, we define $p_{ij}=\frac{p_{i|j}+p_{j|i}}{2n}$.

```{r}
symmetric_probs <- function(P) {
  P = (P + t(P)) / (2*nrow(P))
  return(P)
}
```

In order to initialize the lower dimension probability matrix, we are going to use the method `mvtnorm::rmvnorm` as it is described in the paper: $\mathbf{\mathcal{Y}}^{0} = \{y_1,...,y_n\} \sim \mathcal{N}(0, 10^{-4}\mathbf{I}_n)$ which is assigned to $\mathbf{\mathcal{Y}}^{1}$ and $\mathbf{\mathcal{Y}}^{2}$ (the first two initial states).

## Gradient Descent

```{=tex}
\begin{equation}
\begin{split}
C & = KL(\mathbf{P}\|\mathbf{Q})  \\
  & = \sum_{i}\sum_{j}p_{ij}\log{\frac{p_{ij}}{q_{ij}}} \\
  & = \sum_i\sum_j p_{ij}\left(\log p_{ij}-\log{q_{ij}}\right) \\
  & = \sum_i\sum_j p_{ij}\log{p_{ij}}-p_{ij}\log{q_{ij}}
\end{split}
\end{equation}
```

We define these two auxiliary variables $d_{ij}=\|\mathbf{y}_i-\mathbf{y}_j\|$ and $Z=\sum_{k\neq l}\left(1+d^2_{kl})^{-1}\right)$

```{=tex}
\begin{equation}
\begin{split}
\frac{\partial C}{\partial \mathbf{y}_i} & = \sum_{j \neq i}\left[\frac{\partial C}{\partial d_{ij}}\frac{\partial d_{ij}}{\partial \mathbf{y}_i} +  \frac{\partial C}{\partial d_{ji}}\frac{\partial d_{ji}}{\partial \mathbf{y}_i}\right] \\
  & = \sum_{j \neq i}\left[\frac{\partial d_{ij}}{\partial \mathbf{y}_i} \left(\frac{\partial C}{\partial d_{ij}} +  \frac{\partial C}{\partial d_{ji}}\right)\right] \\
\end{split}
\end{equation}
```

Recall that $\frac{\partial}{\partial x}\sqrt{g(x)}=\frac{1}{2\sqrt{g(x)}}g'(x)$, $\frac{\partial}{\partial \mathbf{y}} \|\mathbf{y}\|^2 = 2 \mathbf{y}$ and $d_{ij}=d_{ji}$

```{=tex}
\begin{equation}
\begin{split}
\frac{\partial d_{ij}}{\partial \mathbf{y}_i}  & = \frac{\partial}{\partial y_i} \|\mathbf{y}_i-\mathbf{y}_j\| \\
                                      & = \frac{\partial}{\partial \mathbf{y}_i} (\|\mathbf{y}_i\|^2+\|\mathbf{y}_j\|^2-2\mathbf{y}_i'\mathbf{y}_j)^{\frac{1}{2}} \\
                                      & = \frac{1}{2}\frac{1}{d_{ij}} \frac{\partial}{\partial \mathbf{y}_i} (\|\mathbf{y}_i\|^2+\cancel{\|\mathbf{y}_j\|^2}-2\mathbf{y}_i'\mathbf{y}_j) \\
                                      & = \frac{1}{2}\frac{1}{d_{ij}} (2\mathbf{y}_i-2\mathbf{y}_j) \\
                                      & = \frac{(\mathbf{y}_i-\mathbf{y}_j)}{d_{ij}} \\
                                      & = \frac{\partial d_{ji}}{\partial \mathbf{y}_i}
\end{split}
\end{equation}
```


```{r}

dij.1 <- function(i, j) {
  sqrt(norm(i, type="2")^2 + norm(j, type="2")^2 - 2 * (t(i) %*% j))
}

dij.2 <- function(i, j) {
  norm(i-j, type="2")
}

y <- data.matrix(iris)[, -5]

# For rows 2 and 3
result1 <- as.numeric(round(jacobian(func=dij.2, x=y[2,], j=y[3,]), digits=7))
result2 <- as.numeric((y[2,]-y[3,])/norm(y[2,]-y[3,], type="2"))
all.equal(result2, result1) # checked
# For row 3 and 2
result3 <- as.numeric(round(jacobian(func=dij.2, x=y[3,], i=y[2,]), digits=7))
result4 <- as.numeric((y[3,]-y[2,])/norm(y[2,]-y[3,], type="2"))
all.equal(result4, result3) # checked
# Checked that both d(d_ij)/dy_i = d(d_ji)/dy_i
```

Recall that $d_{ij}=\|\mathbf{y}_i-\mathbf{y}_j\|$ and  $Z=\sum_{k\neq l}\left(1+d^2_{kl})^{-1}\right)$:

```{=tex}
\begin{equation}
\begin{split}
\frac{\partial C}{\partial d_{ij}}  & = \frac{\partial}{\partial d_{ij}} \sum_{k \neq l} p_{kl}\log{p_{kl}}-p_{kl}\log{q_{kl}} \\
                                    & = \frac{\partial}{\partial d_{ij}} \sum_{k \neq l} -p_{kl}\log{q_{kl}} = 
-\sum_{k \neq l} p_{kl}\frac{\partial{(\log{q_{kl}})}}{\partial d_{ij}} \\
                                    & = -\sum_{k \neq l} p_{kl} \frac{\partial{(\log{\frac{q_{kl}Z}{Z}})}}{\partial d_{ij}} \\ 
                                    & = -\sum_{k \neq l} p_{kl} \left[\frac{\partial{(\log{q_{kl}Z}-\log{Z}})}{\partial d_{ij}} \right] \\
                                    & = -\sum_{k \neq l} p_{kl} \left[\frac{\partial{(\log{q_{kl}Z})}}{\partial d_{ij}}-\frac{\partial{\log{Z}}}{\partial d_{ij}} \right] \\ 
                                    & = -\sum_{k \neq l} p_{kl} \left[ \frac{1}{q_{kl}Z}\frac{\partial{(q_{kl}Z)}}{\partial d_{ij}}-\frac{1}{Z}\frac{\partial{Z}}{\partial d_{ij}} \right] \\
                                    & = -\sum_{k \neq l} p_{kl} \left[ \frac{1}{q_{kl}Z}\frac{\partial{(\frac{(1+d^2_{ij})^{-1}}{\cancel{\sum_{k \neq l}(1+d_{kl}^2)^{-1}}}\cancel{\sum_{k\neq l}(1+d^2_{kl})^{-1})}}}{\partial d_{ij}}-\frac{1}{Z}\frac{\partial{(\sum_{k\neq l}(1+d^2_{kl})^{-1})}}{\partial d_{ij}} \right] \\ 
                                    & = 2\frac{p_{ij}}{q_{ij}Z}(1+d^2_{ij})^{-2}d_{ij}-2\sum_{k \neq l} p_{kl}\frac{(1+d^2_{ij})^{-1}}{Z}(1+d^2_{ij})^{-1}d_{ij} \\ 
                                    & = 2\frac{p_{ij}}{\frac{\cancel{(1+d^2_{ij})^{-1}}}{\cancel{Z}}\cancel{Z}}(1+d^2_{ij})^{-\cancel{2}1}d_{ij}-2\cancel{\sum_{k \neq l} p_{kl}}q_{ij}(1+d^2_{ij})^{-1}d_{ij} \\ 
                                    & =  2p_{ij}(1+d^2_{ij})^{-1}d_{ij}-2q_{ij}(1+d^2_{ij})^{-1}d_{ij} \\ 
                                    & = 2(p_{ij}-q_{ij})(1+d_{ij}^2)^{-1}d_{ij}
\end{split}
\end{equation}
```

```{=tex}
\begin{equation}
\begin{split}
\frac{\partial C}{\partial y_i} & = \sum_{j \neq i}\left[\frac{\partial C}{\partial d_{ij}}\frac{\partial d_{ij}}{\partial y_i} +  \frac{\partial C}{\partial d_{ji}}\frac{\partial d_{ji}}{\partial y_i}\right] \\ 
                                & = \sum_{j \neq i}\left[\frac{\partial d_{ij}}{\partial y_i}\left(\frac{\partial C}{\partial d_{ij}} +  \frac{\partial C}{\partial d_{ij}}\right)\right] \\ 
                                & = 2\sum_{j \neq i}\left[\frac{\partial C}{\partial d_{ij}}\right] \frac{\mathbf{y}_i-\mathbf{y}_j}{d_{ij}} \\
                                & = 2\sum_{j \neq i}\left[2(p_{ij}-q_{ij})(1+d_{ij}^2)^{-1}d_{ij}\right] \frac{\mathbf{y}_i-\mathbf{y}_j}{d_{ij}} \\
                                & = 4\sum_{j \neq i}(p_{ij}-q_{ij})(1+d_{ij}^2)^{-1}\cancel{d_{ij}} \frac{\mathbf{y}_i-\mathbf{y}_j}{\cancel{d_{ij}}} \\
                                & = 4\sum_{j \neq i}(p_{ij}-q_{ij})(1+\|\mathbf{y}_i-\mathbf{y}_j\|^2)^{-1} (\mathbf{y}_i-\mathbf{y}_j)
\end{split}
\end{equation}
```

## Cauchy distribution on the sphere

The following formula corresponds with the probability density function of the Cauchy family on the unit sphere:

$$
f(\mathbf{y}; \boldsymbol{\mu}, \rho) = \frac{\Gamma\{(d+1)/2\}}{2\pi^{(d+1)/2}} \left(\frac{1-\rho^2}{1+\rho^2-2\rho\boldsymbol{\mu}'\mathbf{y}}\right)^d
$$
where $\mathbf{y} \in S^d$, the location parameter $\boldsymbol{\mu} \in S^d$, the concentration parameter $\rho \in [0, 1)$ and the unit sphere in $\mathbb{R}^{d+1}$ denoted by $S^d = \{\mathbf{y} \in \mathbb{R}^{d+1}; \|\mathbf{y}\|=1\}$. When $d=1$ the case is the well-known Wrapped Cauchy or circular Cauchy family.

```{r}
dsphcauchy <- function(y, mu, rho, d=2) {
  (gamma(((d+1)/2))/(2*pi^((d+1)/2))*((1-rho^2)/(1+rho^2-2*rho*(t(mu) %*% y)))^d)
}

library(Directional)
library(Rcpp)
library(rotasym)

sunspots_births$X <-
  cbind(cos(sunspots_births$phi) * cos(sunspots_births$theta),
        cos(sunspots_births$phi) * sin(sunspots_births$theta),
        sin(sunspots_births$phi))

theta_params <- spcauchy.mle(sunspots_births$X)
dsphcauchy(sunspots_births$X[1,], theta_params$mu, theta_params$rho)

library(DirStats)
library(ivdoctr)
n <- nrow(sunspots_births$X)
q <- 2
x <- rbind(diag(1, nrow = q + 1), diag(-1, nrow = q + 1))
bw_rot <- bw_dir_rot(sunspots_births$X)

polysphere <- array(NA, dim=c(100,3, 120))
for(i in seq_len(120)) {
  th <- sample(seq(0, pi/2, l=200), size=100)
  ph <- sample(seq(0, 2*pi, l=200), size=100)
  polysphere[,,i] <- to_sph(th, ph)
}

rgl::plot3d(0, 0, 0, xlim = c(-1, 1), ylim = c(-1, 1), zlim = c(-1, 1),
             radius = 1, type = "s", col = "lightblue", alpha = 0.25,
             lit = FALSE)
# dens <- apply(x, MARGIN=1, FUN=dsphcauchy, mu=theta_params$mu, rho=theta_params$rho)
dens <- apply(x, MARGIN=1, FUN=kde_dir, data = sunspots_births$X, h = bw_rot, L = NULL)
map2color <- function(x, pal, limits = range(x)){
  pal[findInterval(x, seq(limits[1], limits[2], length.out = length(pal) + 1), 
                   all.inside=TRUE)]
}
rgl::points3d(x, col = map2color(dens, pal=heat.colors(10, alpha=0.8)))
```

### Cauchy-SNE

#### High Dimension

For a poly-sphere $\mathbb{S}^{d,r}$ where $r\geq1$ and $d \geq 1$:

```{=tex}
\begin{equation}
\begin{split}
p_{j|i} & = \frac{p_{ji}}{p_{i}} \\
        & = \frac{\prod_{k=1}^r \frac{\Gamma\{(d+1)/2\}}{2\pi^{(d+1)/2}}\left(\frac{1-\rho_{k}^2}{1+\rho_{k}^2-2\rho_{k}\mathbf{x}_{j_{(k)}}'\mathbf{x}_{i_{(k)}}}\right)^d}{\sum_{\ell \neq i} \left[ \prod_{s=1}^r\frac{\Gamma\{(d+1)/2\}}{2\pi^{(d+1)/2}} \left(\frac{1-\rho_{s}^2}{1+\rho_{s}^2-2\rho_{s}\mathbf{x}_{\ell_{(s)}}'\mathbf{x}_{i_{(s)}}}\right)^d \right]} \\
        & = \frac{\left(\frac{\Gamma\{(d+1)/2\}}{2\pi^{(d+1)/2}}\right)^r\prod_{k=1}^r \left(\frac{1-\rho_{k}^2}{1+\rho_{k}^2-2\rho_{k}\mathbf{x}_{j_{(k)}}'\mathbf{x}_{i_{(k)}}}\right)^d}{\left(\frac{\Gamma\{(d+1)/2\}}{2\pi^{(d+1)/2}}\right)^r\sum_{\ell \neq i} \left[ \prod_{s=1}^r \left(\frac{1-\rho_{s}^2}{1+\rho_{s}^2-2\rho_{s}\mathbf{x}_{\ell_{(s)}}'\mathbf{x}_{i_{(s)}}}\right)^d \right]} \\
        & = \frac{\prod_{k=1}^r\left(\frac{1-\rho_{k}^2}{1+\rho_{k}^2-2\rho_{k}\mathbf{x}_{j_{(k)}}'\mathbf{x}_{i_{(k)}}}\right)^d}{\sum_{\ell \neq i}  \left[ \prod_{s=1}^r \left( \frac{1-\rho_{s}^2}{1+\rho_{s}^2-2\rho_{s}\mathbf{x}_{\ell_{(s)}}'\mathbf{x}_{i_{(s)}}}\right)^d \right]} \\
        & = \frac{\left(\prod_{k=1}^r(1-\rho_{k}^2)^d\right)\prod_{k=1}^r(1+\rho_{k}^2-2\rho_{k}\mathbf{x}_{j_{(k)}}'\mathbf{x}_{i_{(k)}})^{-d}}{\sum_{\ell \neq i}  \left[ \left(\prod_{s=1}^r(1-\rho_{s}^2)^d\right)\prod_{s=1}^r(1+\rho_{s}^2-2\rho_{s}\mathbf{x}_{\ell_{(s)}}'\mathbf{x}_{i_{(s)}})^{-d} \right]} \\
        & = \frac{\prod_{k=1}^r(1+\rho_{k}^2-2\rho_{k}\mathbf{x}_{j_{(k)}}'\mathbf{x}_{i_{(k)}})^{-d}}{\sum_{\ell \neq i}  \left[ \prod_{s=1}^r(1+\rho_{s}^2-2\rho_{s}\mathbf{x}_{\ell_{(s)}}'\mathbf{x}_{i_{(s)}})^{-d} \right]}
\end{split}
\end{equation}
```

where the cosine similarity is denoted by $S_c(\mathbf{x}_i, \mathbf{x}_j) = \cos(\theta) = \frac{\mathbf{x}_i\mathbf{x}_j}{\|\mathbf{x}_i\|\|\mathbf{x}_j\|}$. In this case $\|\mathbf{x}_i\|=\|\mathbf{x}_j\|=1$.

We must adapt the configuration of each parameter to have the same perplexity fixed at the beginning, in the same way we had done with the Gaussian case. 

$$
\mathrm{Perp}_i = 2^{H_i}
$$

$$
H_i = - \sum_{j\neq i} p_{j|i}\log p_{j|i}
$$

```{r}
simple_dspcauchy <- function(x, l, i, rho, k, d) {
  ((1 + rho^2 - 2 * rho * t(x[l,,k]) %*% x[i,,k])^(-d))
}

prob_i_spcauchy <- function(x, i, rho, d){
  r <<- dim(x)[3]
  n <<- nrow(x)
  probi_k_spcauchy <- function(j) {
    prod(sapply(X=seq_len(r), FUN=simple_dspcauchy, x=x, i=i, l=j, rho=rho, d=d))
  }
  sum(sapply(seq_len(n)[-i], probi_k_spcauchy))
}

jcondi_spcauchy <- function(x, i, j, rho, d, prob_is=NULL) {
  r <- dim(x)[3]
  if(!is.null(prob_is) && !is.null(prob_is[i])) {
    prob_i <<- prob_is[i]
  } else {
    prob_i <<- prob_i_spcauchy(x, i, rho, d)
  }
  (prod(sapply(1:r, simple_dspcauchy, x=x, i=i, l=j, rho=rho, d=d)) / prob_i)
}

to_perplexity <- function(X, i, rho, d=2, prob_is=NULL) {
  entropy <- function(j) {
    jcondi_value <- jcondi_spcauchy(X, i, j, rho, d, prob_is)
    (jcondi_value * log2(jcondi_value))
  }
  return(2^(-1*sum(sapply(seq_len(nrow(X))[-i], entropy))))
}
```

$$
\frac{\partial s_{ji}}{\partial \mathbf{y}_i} = \frac{\partial}{\partial y_i} \mathbf{y}_j\mathbf{y}_i \\
                                      = \mathbf{y}_j \\
                                      = \frac{\partial s_{ij}}{\partial \mathbf{y}_i}
$$


```{r}
library(numDeriv)
s.ji <- function(i, j) {
  j %*% i
}

jacobian(func=s.ji, x=polysphere[2,,1], j=polysphere[3,,1])

```


$$
\frac{\partial C}{\partial s_{ji}} 
            = \frac{\partial}{\partial s_{ji}} \sum_{k \neq \ell} p_{k\ell}\log{p_{k\ell}}-p_{kl}\log{q_{k\ell}} \\ 
            = \frac{\partial}{\partial s_{ji}} \sum_{k \neq \ell} -p_{k\ell}\log{q_{k\ell}} \\
            = - \sum_{k \neq l} p_{k\ell} \frac{\partial \log{q_{k\ell}}}{\partial s_{ji}} \\
            = -2d\rho p_{ji}(1-\rho^2-2\rho s_{ji})^{-1}+2d\rho q_{ji} (1+\rho^2-2\rho s_{ji})^{-1} \\
            = \frac{2d\rho}{1-\rho^2-2\rho s_{ji}} \left(q_{ji} - p_{ji}\right)
$$

```{r}
library(numDeriv)

s.ji <- function(i, j) {
  t(j) %*% i
}

simple_dspcauchy <- function(s.ji, rho, d) {
  ((1 + rho^2 - 2 * rho * s.ji)^(-d))
}

jcondi_spcauchy_ld <- function(s_ji, Y, i, rho, d) {
  prob_i <- function(Y, i, l, rho, d) {
    s_ji <- s.ji(Y[i,], Y[l,])
    simple_dspcauchy(s_ji, rho, d)
  }
  prob_ij <- simple_dspcauchy(s_ji, rho, d)
  (prob_ij / sum(sapply(1:n, prob_i, Y=Y, i=i, rho=rho, d=d)))
}

call_simple_dspcauchy <- function(x, i, l, rho, d, k) {
    s_ji <- s.ji(x[i,,k], x[l,,k])
    simple_dspcauchy(s_ji, rho, d)
}

prob_i_spcauchy <- function(x, i, rho, d){
  r <<- dim(x)[3]
  n <<- nrow(x)
  probi_k_spcauchy <- function(j) {
    prod(sapply(X=seq_len(r), FUN=call_simple_dspcauchy, x=x, i=i, l=j, rho=rho, d=d))
  }
  sum(sapply(seq_len(n)[-i], probi_k_spcauchy))
}

jcondi_spcauchy <- function(x, i, j, rho, d, prob_is=NULL) {
  r <- dim(x)[3]
  if(!is.null(prob_is) && !is.null(prob_is[i])) {
    prob_i <<- prob_is[i]
  } else {
    prob_i <<- prob_i_spcauchy(x, i, rho, d)
  }
  (prod(sapply(1:r, call_simple_dspcauchy, x=x, i=i, l=j, rho=rho, d=d)) / prob_i)
}

join_prob_spcauchy <- function(s_ji, Y, i, j, rho, d) {
  ((jcondi_spcauchy_ld(s_ji, Y, i, rho, d) + jcondi_spcauchy_ld(s_ji, Y, j, rho, d))/(2*n))
}

kl_cost <- function(X, Y, P, rho, s_ji) {
  n <- nrow(X)
  d <- ncol(X)
  total <- 0
  for(i in seq_len(n)) {
    for(j in seq_len(n)){
      total <- total + (P[i,j] * jacobian(func=function(s_ji, Y, i, j, rho, d){
        join_prob_spcauchy(s_ji, Y, i, j, rho, d)
      }, x=s_ji, Y=Y, i=i, j=j, rho=rho, d=d))
    }
  }
  return(total)
}

jacobian(func=s.ji, x=polysphere[2,,1], j=polysphere[3,,1])

```